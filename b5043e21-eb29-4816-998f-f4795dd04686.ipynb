{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Подготовка\" data-toc-modified-id=\"Подготовка-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Подготовка</a></span></li><li><span><a href=\"#Обучение\" data-toc-modified-id=\"Обучение-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Обучение</a></span></li><li><span><a href=\"#Выводы\" data-toc-modified-id=\"Выводы-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Выводы</a></span></li><li><span><a href=\"#Чек-лист-проверки\" data-toc-modified-id=\"Чек-лист-проверки-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Чек-лист проверки</a></span></li></ul></div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проект для «Викишоп»"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Постройте модель со значением метрики качества *F1* не меньше 0.75. \n",
    "\n",
    "**Инструкция по выполнению проекта**\n",
    "\n",
    "1. Загрузите и подготовьте данные.\n",
    "2. Обучите разные модели. \n",
    "3. Сделайте выводы.\n",
    "\n",
    "Для выполнения проекта применять *BERT* необязательно, но вы можете попробовать.\n",
    "\n",
    "**Описание данных**\n",
    "\n",
    "Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 6 workers.\n",
      "INFO: Pandarallel will use standard multiprocessing data transfer (pipe) to transfer data between the main process and workers.\n",
      "\n",
      "WARNING: You are on Windows. If you detect any issue with pandarallel, be sure you checked out the Troubleshooting page:\n",
      "https://nalepae.github.io/pandarallel/troubleshooting/\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from transformers import (\n",
    "    BertModel,\n",
    "    BertTokenizer,\n",
    "    DistilBertModel,\n",
    "    DistilBertTokenizer\n",
    ")\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "from pandarallel import pandarallel\n",
    "pandarallel.initialize(progress_bar=True)\n",
    "\n",
    "import gc\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: NVIDIA GeForce RTX 3070\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():    \n",
    "    device = torch.device(\"cuda\")\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('datasets/toxic_comments.csv', index_col=[0])\n",
    "df = df.sample(420)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "CACHE_FEATURES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bert(device):\n",
    "    model_class, tokenizer_class, pretrained_weights = (BertModel, BertTokenizer, 'bert-base-uncased')\n",
    "    # model_class, tokenizer_class, pretrained_weights = (DistilBertModel, DistilBertTokenizer, 'distilbert-base-uncased')\n",
    "\n",
    "    tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
    "    model = model_class.from_pretrained(pretrained_weights)\n",
    "    model.cuda(device)\n",
    "\n",
    "    return model, tokenizer\n",
    "\n",
    "def lokenize(x, tokenizer):\n",
    "    return tokenizer.encode(x, truncation=True, max_length=512, add_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_padded_mask(tokenized):\n",
    "    max_len = 0\n",
    "    for i in tokenized.values:\n",
    "        if len(i) > max_len:\n",
    "            max_len = len(i)\n",
    "\n",
    "    padded = np.array([i + [0]*(max_len-len(i)) for i in tokenized.values])\n",
    "    attention_mask = np.where(padded != 0, 1, 0)\n",
    "\n",
    "    padded = torch.tensor(padded)  \n",
    "    attention_mask = torch.tensor(attention_mask)\n",
    "\n",
    "    return padded, attention_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(model, padded, attention_mask, batch_size = 100):\n",
    "    embeddings = []\n",
    "    for i in tqdm(range(math.ceil(padded.shape[0] / batch_size))):\n",
    "        padded_batch = padded[batch_size*i:batch_size*(i+1)].to(device)\n",
    "        attention_mask_batch = attention_mask[batch_size*i:batch_size*(i+1)].to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            batch_embeddings = model(padded_batch, attention_mask=attention_mask_batch)\n",
    "        \n",
    "        embeddings.append(batch_embeddings[0][:,0,:].cpu().numpy())\n",
    "\n",
    "    return np.concatenate(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f35632259f9f467ca4037853bad4d16c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=70), Label(value='0 / 70'))), HBox…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9b1901ac66f4635a3498f420caf96a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model, tokenizer = get_bert(device)\n",
    "\n",
    "tokenized = df['text'].parallel_apply(lokenize, tokenizer=tokenizer)\n",
    "\n",
    "padded, attention_mask = get_padded_mask(tokenized)\n",
    "\n",
    "features = get_features(model, padded, attention_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9047619047619048"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = df['toxic']\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(features, labels)\n",
    "\n",
    "lr_clf = LogisticRegression()\n",
    "lr_clf.fit(train_features, train_labels)\n",
    "\n",
    "\n",
    "lr_clf.score(test_features, test_labels)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer = transformers.BertTokenizer(vocab_file='datasets/ds_bert/vocab.txt')\n",
    "\n",
    "# tokenized = data['text'].apply(lambda x: tokenizer.encode(x, add_special_tokens=True))\n",
    "\n",
    "# max_len = 0\n",
    "# for i in tokenized.values:\n",
    "#     if len(i) > max_len:\n",
    "#         max_len = len(i)\n",
    "\n",
    "# padded = np.array([i + [0]*(max_len - len(i)) for i in tokenized.values])\n",
    "\n",
    "# attention_mask = np.where(padded != 0, 1, 0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Чек-лист проверки"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x]  Jupyter Notebook открыт\n",
    "- [ ]  Весь код выполняется без ошибок\n",
    "- [ ]  Ячейки с кодом расположены в порядке исполнения\n",
    "- [ ]  Данные загружены и подготовлены\n",
    "- [ ]  Модели обучены\n",
    "- [ ]  Значение метрики *F1* не меньше 0.75\n",
    "- [ ]  Выводы написаны"
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 435,
    "start_time": "2023-06-29T12:52:59.806Z"
   },
   {
    "duration": 180,
    "start_time": "2023-06-29T12:53:00.243Z"
   },
   {
    "duration": 2664,
    "start_time": "2023-06-29T12:53:07.700Z"
   },
   {
    "duration": 824,
    "start_time": "2023-06-29T12:53:26.321Z"
   },
   {
    "duration": 8,
    "start_time": "2023-06-29T12:55:28.368Z"
   },
   {
    "duration": 901,
    "start_time": "2023-06-29T12:55:28.379Z"
   },
   {
    "duration": 15,
    "start_time": "2023-06-29T12:55:30.625Z"
   },
   {
    "duration": 720,
    "start_time": "2023-06-29T12:55:52.408Z"
   },
   {
    "duration": 833,
    "start_time": "2023-06-29T13:21:20.097Z"
   },
   {
    "duration": 50,
    "start_time": "2023-06-29T13:23:30.138Z"
   },
   {
    "duration": 3607,
    "start_time": "2023-06-30T10:14:19.342Z"
   },
   {
    "duration": 2428,
    "start_time": "2023-06-30T10:14:22.952Z"
   },
   {
    "duration": 5,
    "start_time": "2023-06-30T10:14:25.383Z"
   },
   {
    "duration": 40147,
    "start_time": "2023-06-30T10:14:25.390Z"
   },
   {
    "duration": 76,
    "start_time": "2023-06-30T10:15:08.929Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.391px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
